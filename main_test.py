#!/usr/bin/env python3
import requests
import json
import readline  # C·∫£i thi·ªán tr·∫£i nghi·ªám input
from tts_module import VietnameseTTS
import re
import os
from pathlib import Path

# --- C·∫•u h√¨nh ---
OLLAMA_API_URL = "http://127.0.0.1:11434/api/chat"
MODEL_NAME = "qwen3:0.6b"  # Thay ƒë·ªïi model n·∫øu c·∫ßn
DATA_FILE = "data.json"  # File ch·ª©a d·ªØ li·ªáu tham kh·∫£o

def load_knowledge_base(file_path):
    """
    ƒê·ªçc file JSON ch·ª©a d·ªØ li·ªáu ki·∫øn th·ª©c.
    
    Args:
        file_path (str): ƒê∆∞·ªùng d·∫´n t·ªõi file JSON
        
    Returns:
        dict: D·ªØ li·ªáu t·ª´ file JSON ho·∫∑c dict r·ªóng n·∫øu c√≥ l·ªói
    """
    try:
        if os.path.exists(file_path):
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                print(f"‚úÖ ƒê√£ t·∫£i d·ªØ li·ªáu t·ª´ {file_path}")
                return data
        else:
            print(f"‚ö†Ô∏è File {file_path} kh√¥ng t·ªìn t·∫°i")
            return {}
    except json.JSONDecodeError:
        print(f"‚ùå L·ªói ƒë·ªçc file JSON: {file_path}")
        return {}
    except Exception as e:
        print(f"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu: {e}")
        return {}

def create_system_prompt_with_data(knowledge_base):
    """
    T·∫°o system prompt bao g·ªìm d·ªØ li·ªáu t·ª´ JSON.
    
    Args:
        knowledge_base (dict): D·ªØ li·ªáu ki·∫øn th·ª©c t·ª´ JSON
        
    Returns:
        str: System prompt ho√†n ch·ªânh
    """
    base_prompt = (
        "B·∫°n l√† Lisa, tr·ª£ l√Ω t∆∞ v·∫•n th√¥ng tin ƒë∆∞·ª£c t·∫°o ra b·ªüi IS LAB c·ªßa tr∆∞·ªùng ƒê·∫°i h·ªçc S∆∞ ph·∫°m K·ªπ thu·∫≠t TP.HCM. "
        "H√£y tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát m·ªôt c√°ch th√¢n thi·ªán v√† ch√≠nh x√°c.\n\n"
    )
    
    if knowledge_base:
        base_prompt += "TH√îNG TIN THAM KH·∫¢O:\n"
        base_prompt += json.dumps(knowledge_base, ensure_ascii=False, indent=2)
        base_prompt += "\n\nH√£y s·ª≠ d·ª•ng th√¥ng tin tr√™n ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng khi ph√π h·ª£p. "
        base_prompt += "N·∫øu th√¥ng tin kh√¥ng c√≥ trong d·ªØ li·ªáu tham kh·∫£o, h√£y tr·∫£ l·ªùi d·ª±a tr√™n ki·∫øn th·ª©c chung c·ªßa b·∫°n."
    
    return base_prompt

def remove_think_blocks(text):
    """Lo·∫°i b·ªè c√°c think blocks kh·ªèi response."""
    return re.sub(r"<think>.*?</think>", "", text, flags=re.DOTALL).strip()

def search_in_knowledge_base(query, knowledge_base):
    """
    T√¨m ki·∫øm th√¥ng tin li√™n quan trong knowledge base.
    
    Args:
        query (str): C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng
        knowledge_base (dict|list): D·ªØ li·ªáu ki·∫øn th·ª©c
        
    Returns:
        list: Danh s√°ch th√¥ng tin li√™n quan
    """
    if not knowledge_base:
        return []
    
    relevant_info = []
    query_lower = query.lower()
    query_words = query_lower.split()
    
    # X·ª≠ l√Ω ƒë·∫∑c bi·ªát cho d·ªØ li·ªáu d·∫°ng prompt-response
    if isinstance(knowledge_base, list) and knowledge_base and isinstance(knowledge_base[0], dict):
        if "prompt" in knowledge_base[0] and "response" in knowledge_base[0]:
            # D·ªØ li·ªáu d·∫°ng FAQ prompt-response
            for i, item in enumerate(knowledge_base):
                prompt = item.get("prompt", "").lower()
                response = item.get("response", "")
                
                # T√≠nh ƒëi·ªÉm t∆∞∆°ng ƒë·ªìng
                score = 0
                for word in query_words:
                    if word in prompt:
                        score += 2  # ƒêi·ªÉm cao h∆°n n·∫øu t·ª´ kh√≥a xu·∫•t hi·ªán trong prompt
                    elif word in response.lower():
                        score += 1  # ƒêi·ªÉm th·∫•p h∆°n n·∫øu t·ª´ kh√≥a xu·∫•t hi·ªán trong response
                
                if score > 0:
                    relevant_info.append({
                        "path": f"faq_{i}",
                        "key": f"Q&A_{i+1}",
                        "value": f"Q: {item['prompt']}\nA: {item['response']}",
                        "score": score,
                        "prompt": item["prompt"],
                        "response": item["response"]
                    })
            
            # S·∫Øp x·∫øp theo ƒëi·ªÉm t∆∞∆°ng ƒë·ªìng
            relevant_info.sort(key=lambda x: x["score"], reverse=True)
            return relevant_info
    
    # X·ª≠ l√Ω d·ªØ li·ªáu d·∫°ng th√¥ng th∆∞·ªùng
    def search_recursive(data, path=""):
        """T√¨m ki·∫øm ƒë·ªá quy trong nested dict/list."""
        if isinstance(data, dict):
            for key, value in data.items():
                current_path = f"{path}.{key}" if path else key
                if isinstance(value, (dict, list)):
                    search_recursive(value, current_path)
                else:
                    if any(keyword in str(value).lower() or keyword in key.lower() 
                          for keyword in query_words):
                        relevant_info.append({
                            "path": current_path,
                            "key": key,
                            "value": value
                        })
        elif isinstance(data, list):
            for i, item in enumerate(data):
                current_path = f"{path}[{i}]" if path else f"item_{i}"
                if isinstance(item, (dict, list)):
                    search_recursive(item, current_path)
                else:
                    if any(keyword in str(item).lower() for keyword in query_words):
                        relevant_info.append({
                            "path": current_path,
                            "key": f"item_{i}",
                            "value": item
                        })
    
    search_recursive(knowledge_base)
    return relevant_info

class QwenInteractiveChat:
    """
    L·ªõp qu·∫£n l√Ω phi√™n chat t∆∞∆°ng t√°c v·ªõi Qwen, TTS v√† JSON data.
    """
    def __init__(self, enable_tts=True, lang='vi', data_file=DATA_FILE):
        """
        Kh·ªüi t·∫°o session chat.
        
        Args:
            enable_tts (bool): B·∫≠t/t·∫Øt TTS.
            lang (str): Ng√¥n ng·ªØ cho TTS.
            data_file (str): ƒê∆∞·ªùng d·∫´n t·ªõi file JSON ch·ª©a d·ªØ li·ªáu.
        """
        # T·∫£i knowledge base
        self.knowledge_base = load_knowledge_base(data_file)
        
        # T·∫°o system prompt v·ªõi d·ªØ li·ªáu
        system_prompt = create_system_prompt_with_data(self.knowledge_base)
        self.messages = [{"role": "system", "content": system_prompt}]
        
        # C·∫•u h√¨nh TTS
        self.enable_tts = enable_tts
        if self.enable_tts:
            self.tts = VietnameseTTS(lang=lang)
        else:
            self.tts = None

    def reload_knowledge_base(self, data_file=DATA_FILE):
        """
        T·∫£i l·∫°i d·ªØ li·ªáu t·ª´ file JSON.
        
        Args:
            data_file (str): ƒê∆∞·ªùng d·∫´n t·ªõi file JSON
        """
        self.knowledge_base = load_knowledge_base(data_file)
        system_prompt = create_system_prompt_with_data(self.knowledge_base)
        self.messages[0] = {"role": "system", "content": system_prompt}
        print("üîÑ ƒê√£ t·∫£i l·∫°i d·ªØ li·ªáu v√† c·∫≠p nh·∫≠t system prompt")

    def _enhance_user_query(self, user_input):
        """
        TƒÉng c∆∞·ªùng c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng b·∫±ng th√¥ng tin li√™n quan t·ª´ knowledge base.
        
        Args:
            user_input (str): C√¢u h·ªèi g·ªëc c·ªßa ng∆∞·ªùi d√πng
            
        Returns:
            str: C√¢u h·ªèi ƒë∆∞·ª£c tƒÉng c∆∞·ªùng v·ªõi context
        """
        if not self.knowledge_base:
            return user_input
        
        # T√¨m th√¥ng tin li√™n quan
        relevant_info = search_in_knowledge_base(user_input, self.knowledge_base)
        
        if relevant_info:
            # X·ª≠ l√Ω ƒë·∫∑c bi·ªát cho d·ªØ li·ªáu FAQ
            if relevant_info and "prompt" in relevant_info[0]:
                enhanced_query = f"C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng: {user_input}\n\n"
                enhanced_query += "C√°c c√¢u h·ªèi v√† c√¢u tr·∫£ l·ªùi t∆∞∆°ng t·ª± t·ª´ c∆° s·ªü d·ªØ li·ªáu:\n"
                
                for i, info in enumerate(relevant_info[:2]):  # L·∫•y 2 c√¢u h·ªèi t∆∞∆°ng t·ª± nh·∫•t
                    enhanced_query += f"\n{i+1}. C√¢u h·ªèi: {info['prompt']}\n"
                    enhanced_query += f"   Tr·∫£ l·ªùi: {info['response']}\n"
                
                enhanced_query += f"\nD·ª±a tr√™n th√¥ng tin tr√™n, h√£y tr·∫£ l·ªùi c√¢u h·ªèi: '{user_input}' m·ªôt c√°ch t·ª± nhi√™n v√† ch√≠nh x√°c."
                return enhanced_query
            else:
                # X·ª≠ l√Ω d·ªØ li·ªáu th√¥ng th∆∞·ªùng
                enhanced_query = f"C√¢u h·ªèi: {user_input}\n\nTh√¥ng tin li√™n quan t·ª´ d·ªØ li·ªáu:\n"
                for info in relevant_info[:3]:  # Gi·ªõi h·∫°n 3 th√¥ng tin li√™n quan nh·∫•t
                    enhanced_query += f"- {info['key']}: {info['value']}\n"
                enhanced_query += "\nVui l√≤ng tr·∫£ l·ªùi d·ª±a tr√™n th√¥ng tin tr√™n n·∫øu ph√π h·ª£p."
                return enhanced_query
        
        return user_input

    def _get_qwen_response(self, stream=True):
        """
        G·ª≠i y√™u c·∫ßu ƒë·∫øn Ollama v√† x·ª≠ l√Ω ph·∫£n h·ªìi.
        
        Args:
            stream (bool): B·∫≠t/t·∫Øt ch·∫ø ƒë·ªô stream.
            
        Returns:
            str: To√†n b·ªô n·ªôi dung ph·∫£n h·ªìi t·ª´ model, ho·∫∑c None n·∫øu c√≥ l·ªói.
        """
        payload = {
            "model": MODEL_NAME,
            "messages": self.messages,
            "stream": stream,
            "think": False
        }
        
        full_response = ""
        try:
            # G·ª≠i y√™u c·∫ßu POST
            response_stream = requests.post(OLLAMA_API_URL, json=payload, stream=stream)
            response_stream.raise_for_status()
            
            print("ü§ñ Lisa: ", end="", flush=True)
            
            # X·ª≠ l√Ω t·ª´ng d√≤ng d·ªØ li·ªáu stream
            for line in response_stream.iter_lines():
                if line:
                    data = json.loads(line.decode('utf-8'))
                    chunk = data.get("message", {}).get("content", "")
                    print(chunk, end="", flush=True)
                    full_response += chunk
                    
                    # D·ª´ng l·∫°i khi message cu·ªëi c√πng ƒë∆∞·ª£c g·ª≠i
                    if data.get("done"):
                        break
            
            print()  # In d√≤ng m·ªõi sau khi ho√†n th√†nh
            return full_response
            
        except requests.RequestException as e:
            print(f"\n‚ùå L·ªói khi g·ªçi API Ollama: {e}")
            return None
        except json.JSONDecodeError:
            print("\n‚ùå L·ªói gi·∫£i m√£ JSON t·ª´ API.")
            return None

    def show_help(self):
        """Hi·ªÉn th·ªã h∆∞·ªõng d·∫´n s·ª≠ d·ª•ng."""
        print("\nüìã H∆Ø·ªöNG D·∫™N S·ª¨ D·ª§NG:")
        print("‚Ä¢ G√µ c√¢u h·ªèi b√¨nh th∆∞·ªùng ƒë·ªÉ chat")
        print("‚Ä¢ 'reload' - T·∫£i l·∫°i d·ªØ li·ªáu t·ª´ JSON")
        print("‚Ä¢ 'info' - Xem th√¥ng tin v·ªÅ d·ªØ li·ªáu ƒë√£ t·∫£i")
        print("‚Ä¢ 'help' - Hi·ªÉn th·ªã h∆∞·ªõng d·∫´n n√†y")
        print("‚Ä¢ 'quit' ho·∫∑c 'exit' - Tho√°t ch∆∞∆°ng tr√¨nh")
        print()

    def show_data_info(self):
        """Hi·ªÉn th·ªã th√¥ng tin v·ªÅ d·ªØ li·ªáu ƒë√£ t·∫£i."""
        if not self.knowledge_base:
            print("üìä Ch∆∞a c√≥ d·ªØ li·ªáu n√†o ƒë∆∞·ª£c t·∫£i.")
            return
        
        print(f"üìä TH√îNG TIN D·ªÆ LI·ªÜU:")
        
        # X·ª≠ l√Ω c·∫£ dictionary v√† list
        if isinstance(self.knowledge_base, dict):
            print(f"‚Ä¢ Lo·∫°i d·ªØ li·ªáu: Dictionary")
            print(f"‚Ä¢ S·ªë l∆∞·ª£ng key ch√≠nh: {len(self.knowledge_base)}")
            print(f"‚Ä¢ C√°c key ch√≠nh: {list(self.knowledge_base.keys())}")
        elif isinstance(self.knowledge_base, list):
            print(f"‚Ä¢ Lo·∫°i d·ªØ li·ªáu: List")
            print(f"‚Ä¢ S·ªë l∆∞·ª£ng items: {len(self.knowledge_base)}")
            
            # Ki·ªÉm tra xem c√≥ ph·∫£i l√† d·ªØ li·ªáu FAQ kh√¥ng
            if (self.knowledge_base and isinstance(self.knowledge_base[0], dict) and
                "prompt" in self.knowledge_base[0] and "response" in self.knowledge_base[0]):
                print(f"‚Ä¢ ƒê·ªãnh d·∫°ng: FAQ (Prompt-Response)")
                print(f"‚Ä¢ S·ªë c√¢u h·ªèi c√≥ s·∫µn: {len(self.knowledge_base)}")
                
                # Hi·ªÉn th·ªã v√†i c√¢u h·ªèi m·∫´u
                print("‚Ä¢ M·ªôt s·ªë c√¢u h·ªèi m·∫´u:")
                for i, item in enumerate(self.knowledge_base[:3]):
                    print(f"  {i+1}. {item.get('prompt', 'N/A')}")
                if len(self.knowledge_base) > 3:
                    print(f"  ... v√† {len(self.knowledge_base) - 3} c√¢u h·ªèi kh√°c")
            elif self.knowledge_base and isinstance(self.knowledge_base[0], dict):
                first_item_keys = list(self.knowledge_base[0].keys())
                print(f"‚Ä¢ Keys c·ªßa item ƒë·∫ßu ti√™n: {first_item_keys}")
        else:
            print(f"‚Ä¢ Lo·∫°i d·ªØ li·ªáu: {type(self.knowledge_base).__name__}")
        
        def count_items(data, depth=0):
            count = 0
            if isinstance(data, dict):
                count += len(data)
                for value in data.values():
                    if isinstance(value, (dict, list)):
                        count += count_items(value, depth + 1)
            elif isinstance(data, list):
                count += len(data)
                for item in data:
                    if isinstance(item, (dict, list)):
                        count += count_items(item, depth + 1)
            return count
        
        total_items = count_items(self.knowledge_base)
        print(f"‚Ä¢ T·ªïng s·ªë items: {total_items}")
        print()

    def start(self):
        """
        B·∫Øt ƒë·∫ßu v√≤ng l·∫∑p chat t∆∞∆°ng t√°c.
        """
        print("üéØ Chatbot Lisa v·ªõi d·ªØ li·ªáu JSON ƒë√£ s·∫µn s√†ng!")
        print("   (G√µ 'help' ƒë·ªÉ xem h∆∞·ªõng d·∫´n)")
        print("=" * 50)
        
        # Hi·ªÉn th·ªã th√¥ng tin d·ªØ li·ªáu ƒë√£ t·∫£i
        if self.knowledge_base:
            self.show_data_info()
        
        try:
            while True:
                # L·∫•y input t·ª´ ng∆∞·ªùi d√πng
                user_input = input("üë§ B·∫°n: ").strip()
                
                if not user_input:
                    continue
                
                # X·ª≠ l√Ω c√°c l·ªánh ƒë·∫∑c bi·ªát
                if user_input.lower() in ["quit", "exit"]:
                    print("üëã T·∫°m bi·ªát!")
                    break
                elif user_input.lower() == "help":
                    self.show_help()
                    continue
                elif user_input.lower() == "info":
                    self.show_data_info()
                    continue
                elif user_input.lower() == "reload":
                    self.reload_knowledge_base()
                    continue
                
                # TƒÉng c∆∞·ªùng c√¢u h·ªèi v·ªõi th√¥ng tin t·ª´ knowledge base
                enhanced_query = self._enhance_user_query(user_input)
                
                # Th√™m tin nh·∫Øn c·ªßa ng∆∞·ªùi d√πng v√†o l·ªãch s·ª≠ (s·ª≠ d·ª•ng c√¢u h·ªèi g·ªëc)
                self.messages.append({"role": "user", "content": enhanced_query})
                
                # L·∫•y ph·∫£n h·ªìi t·ª´ Qwen
                qwen_response = self._get_qwen_response()
                clean_response = remove_think_blocks(qwen_response)
                
                if clean_response:
                    # Th√™m ph·∫£n h·ªìi c·ªßa Qwen v√†o l·ªãch s·ª≠ ƒë·ªÉ duy tr√¨ ng·ªØ c·∫£nh
                    self.messages.append({"role": "assistant", "content": clean_response})
                    
                    # Ph√°t gi·ªçng n√≥i n·∫øu TTS ƒë∆∞·ª£c b·∫≠t
                    if self.enable_tts and self.tts:
                        print("üîä ƒêang ph√°t gi·ªçng n√≥i...")
                        self.tts.text_to_speech(clean_response, auto_play=True, auto_delete=True)
                
                print("-" * 50)
                
        except (KeyboardInterrupt, EOFError):
            print("\nüëã T·∫°m bi·ªát!")
        finally:
            # D·ªçn d·∫πp t√†i nguy√™n
            if self.enable_tts and self.tts:
                self.tts.cleanup()

def create_sample_data_file():
    """
    T·∫°o file data.json m·∫´u n·∫øu ch∆∞a t·ªìn t·∫°i.
    """
    if not os.path.exists(DATA_FILE):
        sample_data = {
            "thong_tin_truong": {
                "ten": "Tr∆∞·ªùng ƒê·∫°i h·ªçc S∆∞ ph·∫°m K·ªπ thu·∫≠t TP.HCM",
                "ten_viet_tat": "HCMUTE",
                "dia_chi": "1 V√µ VƒÉn Ng√¢n, Th·ªß ƒê·ª©c, TP.HCM",
                "website": "https://hcmute.edu.vn",
                "dien_thoai": "028-38968641"
            },
            "khoa_vien": {
                "CNTT": {
                    "ten_day_du": "Khoa C√¥ng ngh·ªá Th√¥ng tin",
                    "truong_khoa": "TS. Nguy·ªÖn VƒÉn A",
                    "cac_nganh": ["C√¥ng ngh·ªá Th√¥ng tin", "Khoa h·ªçc M√°y t√≠nh", "An to√†n Th√¥ng tin"]
                },
                "DIEN": {
                    "ten_day_du": "Khoa ƒêi·ªán - ƒêi·ªán t·ª≠",
                    "truong_khoa": "TS. Tr·∫ßn VƒÉn B",
                    "cac_nganh": ["K·ªπ thu·∫≠t ƒêi·ªán", "K·ªπ thu·∫≠t ƒêi·ªán t·ª≠", "T·ª± ƒë·ªông h√≥a"]
                }
            },
            "is_lab": {
                "ten": "Ph√≤ng th√≠ nghi·ªám H·ªá th·ªëng Th√¥ng tin (IS LAB)",
                "mo_ta": "Ph√≤ng lab nghi√™n c·ª©u v·ªÅ AI, Machine Learning v√† c√°c h·ªá th·ªëng th√¥ng tin",
                "thanh_vien": ["Sinh vi√™n CNTT", "Nghi√™n c·ª©u sinh", "Gi·∫£ng vi√™n h∆∞·ªõng d·∫´n"],
                "du_an": ["Chatbot AI", "H·ªá th·ªëng qu·∫£n l√Ω", "·ª®ng d·ª•ng mobile"]
            },
            "hoc_phi": {
                "dai_hoc": {
                    "hoc_phi_1_tin_chi": 330000,
                    "don_vi": "VND",
                    "ghi_chu": "H·ªçc ph√≠ c√≥ th·ªÉ thay ƒë·ªïi theo t·ª´ng nƒÉm h·ªçc"
                }
            },
            "lien_he": {
                "phong_dao_tao": "028-38968641",
                "phong_ctsv": "028-38968642",
                "email": "info@hcmute.edu.vn"
            }
        }
        
        with open(DATA_FILE, 'w', encoding='utf-8') as f:
            json.dump(sample_data, f, ensure_ascii=False, indent=2)
        print(f"‚úÖ ƒê√£ t·∫°o file m·∫´u {DATA_FILE}")

if __name__ == "__main__":
    # T·∫°o file d·ªØ li·ªáu m·∫´u n·∫øu ch∆∞a c√≥
    create_sample_data_file()
    
    # Kh·ªüi t·∫°o v√† b·∫Øt ƒë·∫ßu session chat
    chat_session = QwenInteractiveChat(enable_tts=True)
    chat_session.start()